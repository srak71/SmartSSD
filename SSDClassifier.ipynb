{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbd691a",
   "metadata": {},
   "source": [
    "# An Elementary Image Classifier for Solid State Drive Production Error\n",
    "\n",
    "**Author:** *Saransh Rakshak* \n",
    "\n",
    "**Github:**  [srak71](https://github.com/srak71) (Click to open)\n",
    "\n",
    "**LinkedIn:** [srak71](https://www.linkedin.com/in/srak71/) (Click to open)\n",
    "\n",
    "**Date:** *May 16, 2025*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7580c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344d7b0b",
   "metadata": {},
   "source": [
    "The following is my attempt to show Western Digital hiring team that I would make a perfect candidate for the *Summer 2025 Intern, Failure Analysis Engineering* role. This basic project accomplishes the *\"Essential Duties And Responsibilities\"* posted in the job description. I hope you enjoy!\n",
    "\n",
    "The NEU-CLS dataset has 1800 grayscale images of steel surface defects (200Ã—200 pixels) in six classes: rolled-in scale, patches, crazing, pitted surface, inclusion, and scratches.\n",
    "\n",
    "The dataset is organized into subdirectories per class in separate train/images and validation/images directories. Example: training images might be in .../train/images/scratches/ and similarly for the other classes. \n",
    "\n",
    "The steps for training the classification model are as follows:\n",
    "\n",
    "**Part 1: Data Processing**\n",
    "\n",
    "    1a. Proper loading of NEU data\n",
    "    1b. Augment training set and normalize both sets for unified comparison\n",
    "  \n",
    "**Part 2: Model Creation and Training Parameters**\n",
    "\n",
    "    2a. Defining Convolution Neural Net Model\n",
    "    2b. Establishing Callbacks to stop training when optimization met.\n",
    "  \n",
    "**Part 3: Training and Selecting Optimal Model**\n",
    "\n",
    "    3a. Training CNN with established parameters, and saving best model into 'SmartSSD/best_model.keras'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd4f242",
   "metadata": {},
   "source": [
    "# Part 1: Data Processing\n",
    "\n",
    "## 1a. Proper loading of NEU data.\n",
    "\n",
    "For reproducability I am using Python's **os** package to establish given user's current working directory. Then joining with location of my train & validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47714c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user dir\n",
    "current_dir= os.getcwd()\n",
    "\n",
    "# known filepaths\n",
    "train_dir= os.path.join(current_dir, \"NEU-CLS\", \"train\", \"images\")\n",
    "val_dir= os.path.join(current_dir, \"NEU-CLS\", \"validation\", \"images\")\n",
    "\n",
    "# unified variables\n",
    "image_size= (128, 128)\n",
    "batch_size= 32 # number of images to process before updating mode weights \n",
    "epochs= 10 # number of times entire dataset trains on model\n",
    "num_classes= 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f04fd3",
   "metadata": {},
   "source": [
    "## 1b. Augment training set and normalize both sets for unified comparison\n",
    "\n",
    "For loading my images and labels I am using Keras package to read directories of images. My code uses TF's *ImageDataGenerator()* instead of the basic *image_dataset_from_directory()* for integrated data augmentation such as normalization (*rescale=1. / 255*) and transformations (to the training data only). By augmenting I am expanding the size of the dataset so my model has more images to train on without having to gather any new data. \n",
    "\n",
    "- Normalization: All images rescaled to be in range(0,1) by dividing by 225 and resizing to 128x128 resolution. *color_mode='greyscale'* specified so each image has one channel.\n",
    "\n",
    "- Augmentation: My transformations to the training data includes rotation and reflection (flip), as well as brightness transformation. Limiting range of augmentation to at most 20% for ensuring the image remains usable. No transformations/augmentations made to validation data to avoid leaking val information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af7347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmenting training images by rotating flipping and altering brightness\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,\n",
    "                                                                rotation_range=20, # random rotations\n",
    "                                                                horizontal_flip=True, # random horizontal flips\n",
    "                                                                brightness_range=(0.8, 1.2)) # random brightness\n",
    "\n",
    "# just normalizing in the case of val images\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) \n",
    "\n",
    "# actually generating the image defined from my ImageDataGenerator() function\n",
    "train_gen = train_datagen.flow_from_directory(train_dir,\n",
    "                                              target_size=image_size,\n",
    "                                              color_mode='grayscale',\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(val_dir,\n",
    "                                          target_size=image_size,\n",
    "                                          color_mode='grayscale',\n",
    "                                          batch_size=batch_size,\n",
    "                                          class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37800c92",
   "metadata": {},
   "source": [
    "# Part 2. Defining Convolution Neural Net Model\n",
    "\n",
    "## 2a. I will create a basic **Convolutional Neural Network (CNN)** consisting of three blocks and a classification head. \n",
    "\n",
    "Block 1, 2, 3: \n",
    "\n",
    "> Layer 1. Convolution layer with **ReLu** activation function. *Conv2D()*\n",
    ">\n",
    "> Layer 2. Establishing limitations to my batch pool_size. *MaxPooling2D()*\n",
    ">\n",
    "> Layer 3. *Dropout()* layer limiting overfitting (also normalizing).\n",
    "\n",
    "Classification Head:\n",
    "\n",
    "> Layer 1: *Flatten()* layer to  the feature maps.\n",
    ">\n",
    "> Layer 2: *Dense()* layer using **ReLU** as my activation.\n",
    "> \n",
    "> Layer 3: *Dropout()* layer to limit overfitting model.\n",
    ">\n",
    "> Layer 4: *Dense()* layer but now using number of types of defects (classes), thus switch to **softmax** activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c8a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Block 1\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation= 'relu', input_shape= (128, 128, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Block 2\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation= 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2,2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Block 3\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation= 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Classification head\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation= 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_classes, activation= 'softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf64642",
   "metadata": {},
   "source": [
    "Finally, my last block will compile my established CNN. Since there are multiple different classifications possible for image, I will compile model with **Adam** as my optimizer and measure by categorical cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c644fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba45d9",
   "metadata": {},
   "source": [
    "## 2b. Establishing Callbacks to stop training when optimization met.\n",
    "\n",
    "I will train my model with the entire dataset (*epochs=*) 10 times. While fitting the model using *model.fit()* in Part 3, Keras autoprints training and validation accuracy/loss for every epoch. I will set *callbacks=* 'EarlyStopping' and 'ModelCheckpoint' in *model.fit()* to accomplish the following:\n",
    "\n",
    "- EarlyStopping: While monitoring training loss, I will stop training if model performance does not improve for 3 epochs. For instance, if epoch 2 has val_loss of 0.1 (hypothetically), and epochs 3, 4, 5 have val_loss greater than 0.1, training should stop after epoch 5, and the model weights from epoch 2 should be loaded.\n",
    "\n",
    "- ModelCheckpoint: I save model weights to file **best_model.keras** whenever I get improvement of performance on the validation set by setting *save_best_only=* True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b82715",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor= 'val_loss',\n",
    "                                             patience= 3, # test for improvement in next 3, if none stop and load old\n",
    "                                             restore_best_weights= True,\n",
    "                                             verbose= 1)\n",
    "\n",
    "# after stopping loading weights from old epoch (the one with the lowest val loss)\n",
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint('best_model.keras',\n",
    "                                                     monitor= 'val_loss',\n",
    "                                                     save_best_only= True,\n",
    "                                                     verbose= 1)\n",
    "\n",
    "callbacks = [earlyStop, modelCheckpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d17dd7",
   "metadata": {},
   "source": [
    "# Part 3: Training and Selecting Optimal Model\n",
    "\n",
    "## 3a. Training and saving my best performing model to 'SmartSSD/best_model.keras'.\n",
    "\n",
    "In order to use the trained model for classification on new data, I will save it to my directory in file **best_model.keras**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219db9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_gen,\n",
    "                    epochs= epochs,\n",
    "                    validation_data= val_gen,\n",
    "                    callbacks= callbacks,\n",
    "                    verbose= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062d5ae6",
   "metadata": {},
   "source": [
    "Now I am chaining our Callbacks to allow for more data training before picking optimal model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c320cd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlyStop = tf.keras.callbacks.EarlyStopping(monitor= 'val_loss',\n",
    "                                             patience= 5, # test for improvement in next 3, if none stop and load old\n",
    "                                             restore_best_weights= True,\n",
    "                                             verbose= 1)\n",
    "\n",
    "# after stopping loading weights from old epoch (the one with the lowest val loss)\n",
    "modelCheckpoint = tf.keras.callbacks.ModelCheckpoint('best_model.keras',\n",
    "                                                     monitor= 'val_loss',\n",
    "                                                     save_best_only= True,\n",
    "                                                     verbose= 1)\n",
    "\n",
    "callbacks = [earlyStop, modelCheckpoint]\n",
    "\n",
    "history = model.fit(train_gen,\n",
    "                    epochs= epochs,\n",
    "                    validation_data= val_gen,\n",
    "                    callbacks= callbacks,\n",
    "                    verbose= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8764442e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cf4de8d",
   "metadata": {},
   "source": [
    "**End of Notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3989b0b7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
